{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: MLP Model Implementation & Experiment Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement a Multi-Layer Perceptron (MLP) Using the Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchinfo import summary\n",
    "from tqdm.auto import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "PyTorch Version: 2.6.0+cu124\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.4\n",
      "GPU Name: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m23110222\u001b[0m (\u001b[33m23110222-indian-institute-of-technology-gandhinagar\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nishuz/Desktop/College/AI_STT/Assignments/6/CS203-Lab06/wandb/run-20250224_020703-yf216x6a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6/runs/yf216x6a' target=\"_blank\">rich-leaf-14</a></strong> to <a href='https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6' target=\"_blank\">https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6/runs/yf216x6a' target=\"_blank\">https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6/runs/yf216x6a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 32, 'epochs': 500, 'architecture': 'MLP (4-16-3)', 'activation': 'ReLU', 'loss_function': 'CrossEntropyLoss', 'optimizer': 'Adam', 'layers': 3, 'neurons': {'input': 4, 'hidden': 16, 'output': 3}, 'trainable_params': 131, 'non-trainable_params': 0, 'dataset': 'Iris'}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,\n",
    "    \"architecture\": \"MLP (4-16-3)\",\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"loss_function\": \"CrossEntropyLoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"layers\": 3,\n",
    "    \"neurons\": { \n",
    "        \"input\": 4, \n",
    "        \"hidden\": 16, \n",
    "        \"output\": 3 \n",
    "    },\n",
    "    \"trainable_params\": 131,\n",
    "    \"non-trainable_params\": 0,\n",
    "    \"dataset\": \"Iris\",\n",
    "}\n",
    "\n",
    "wandb.init(project=\"cs203-assignment-6\", config=config)\n",
    "wandb.config.update(config, allow_val_change=True)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([150])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = torch.tensor(iris.data)\n",
    "y = torch.tensor(iris.target)\n",
    "\n",
    "display(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Feature Values to [0, 1] and One-hot Encoding the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2222, 0.6250, 0.0678, 0.0417],\n",
       "        [0.1667, 0.4167, 0.0678, 0.0417],\n",
       "        [0.1111, 0.5000, 0.0508, 0.0417],\n",
       "        [0.0833, 0.4583, 0.0847, 0.0417],\n",
       "        [0.1944, 0.6667, 0.0678, 0.0417],\n",
       "        [0.3056, 0.7917, 0.1186, 0.1250],\n",
       "        [0.0833, 0.5833, 0.0678, 0.0833],\n",
       "        [0.1944, 0.5833, 0.0847, 0.0417],\n",
       "        [0.0278, 0.3750, 0.0678, 0.0417],\n",
       "        [0.1667, 0.4583, 0.0847, 0.0000],\n",
       "        [0.3056, 0.7083, 0.0847, 0.0417],\n",
       "        [0.1389, 0.5833, 0.1017, 0.0417],\n",
       "        [0.1389, 0.4167, 0.0678, 0.0000],\n",
       "        [0.0000, 0.4167, 0.0169, 0.0000],\n",
       "        [0.4167, 0.8333, 0.0339, 0.0417],\n",
       "        [0.3889, 1.0000, 0.0847, 0.1250],\n",
       "        [0.3056, 0.7917, 0.0508, 0.1250],\n",
       "        [0.2222, 0.6250, 0.0678, 0.0833],\n",
       "        [0.3889, 0.7500, 0.1186, 0.0833],\n",
       "        [0.2222, 0.7500, 0.0847, 0.0833],\n",
       "        [0.3056, 0.5833, 0.1186, 0.0417],\n",
       "        [0.2222, 0.7083, 0.0847, 0.1250],\n",
       "        [0.0833, 0.6667, 0.0000, 0.0417],\n",
       "        [0.2222, 0.5417, 0.1186, 0.1667],\n",
       "        [0.1389, 0.5833, 0.1525, 0.0417],\n",
       "        [0.1944, 0.4167, 0.1017, 0.0417],\n",
       "        [0.1944, 0.5833, 0.1017, 0.1250],\n",
       "        [0.2500, 0.6250, 0.0847, 0.0417],\n",
       "        [0.2500, 0.5833, 0.0678, 0.0417],\n",
       "        [0.1111, 0.5000, 0.1017, 0.0417],\n",
       "        [0.1389, 0.4583, 0.1017, 0.0417],\n",
       "        [0.3056, 0.5833, 0.0847, 0.1250],\n",
       "        [0.2500, 0.8750, 0.0847, 0.0000],\n",
       "        [0.3333, 0.9167, 0.0678, 0.0417],\n",
       "        [0.1667, 0.4583, 0.0847, 0.0417],\n",
       "        [0.1944, 0.5000, 0.0339, 0.0417],\n",
       "        [0.3333, 0.6250, 0.0508, 0.0417],\n",
       "        [0.1667, 0.6667, 0.0678, 0.0000],\n",
       "        [0.0278, 0.4167, 0.0508, 0.0417],\n",
       "        [0.2222, 0.5833, 0.0847, 0.0417],\n",
       "        [0.1944, 0.6250, 0.0508, 0.0833],\n",
       "        [0.0556, 0.1250, 0.0508, 0.0833],\n",
       "        [0.0278, 0.5000, 0.0508, 0.0417],\n",
       "        [0.1944, 0.6250, 0.1017, 0.2083],\n",
       "        [0.2222, 0.7500, 0.1525, 0.1250],\n",
       "        [0.1389, 0.4167, 0.0678, 0.0833],\n",
       "        [0.2222, 0.7500, 0.1017, 0.0417],\n",
       "        [0.0833, 0.5000, 0.0678, 0.0417],\n",
       "        [0.2778, 0.7083, 0.0847, 0.0417],\n",
       "        [0.1944, 0.5417, 0.0678, 0.0417],\n",
       "        [0.7500, 0.5000, 0.6271, 0.5417],\n",
       "        [0.5833, 0.5000, 0.5932, 0.5833],\n",
       "        [0.7222, 0.4583, 0.6610, 0.5833],\n",
       "        [0.3333, 0.1250, 0.5085, 0.5000],\n",
       "        [0.6111, 0.3333, 0.6102, 0.5833],\n",
       "        [0.3889, 0.3333, 0.5932, 0.5000],\n",
       "        [0.5556, 0.5417, 0.6271, 0.6250],\n",
       "        [0.1667, 0.1667, 0.3898, 0.3750],\n",
       "        [0.6389, 0.3750, 0.6102, 0.5000],\n",
       "        [0.2500, 0.2917, 0.4915, 0.5417],\n",
       "        [0.1944, 0.0000, 0.4237, 0.3750],\n",
       "        [0.4444, 0.4167, 0.5424, 0.5833],\n",
       "        [0.4722, 0.0833, 0.5085, 0.3750],\n",
       "        [0.5000, 0.3750, 0.6271, 0.5417],\n",
       "        [0.3611, 0.3750, 0.4407, 0.5000],\n",
       "        [0.6667, 0.4583, 0.5763, 0.5417],\n",
       "        [0.3611, 0.4167, 0.5932, 0.5833],\n",
       "        [0.4167, 0.2917, 0.5254, 0.3750],\n",
       "        [0.5278, 0.0833, 0.5932, 0.5833],\n",
       "        [0.3611, 0.2083, 0.4915, 0.4167],\n",
       "        [0.4444, 0.5000, 0.6441, 0.7083],\n",
       "        [0.5000, 0.3333, 0.5085, 0.5000],\n",
       "        [0.5556, 0.2083, 0.6610, 0.5833],\n",
       "        [0.5000, 0.3333, 0.6271, 0.4583],\n",
       "        [0.5833, 0.3750, 0.5593, 0.5000],\n",
       "        [0.6389, 0.4167, 0.5763, 0.5417],\n",
       "        [0.6944, 0.3333, 0.6441, 0.5417],\n",
       "        [0.6667, 0.4167, 0.6780, 0.6667],\n",
       "        [0.4722, 0.3750, 0.5932, 0.5833],\n",
       "        [0.3889, 0.2500, 0.4237, 0.3750],\n",
       "        [0.3333, 0.1667, 0.4746, 0.4167],\n",
       "        [0.3333, 0.1667, 0.4576, 0.3750],\n",
       "        [0.4167, 0.2917, 0.4915, 0.4583],\n",
       "        [0.4722, 0.2917, 0.6949, 0.6250],\n",
       "        [0.3056, 0.4167, 0.5932, 0.5833],\n",
       "        [0.4722, 0.5833, 0.5932, 0.6250],\n",
       "        [0.6667, 0.4583, 0.6271, 0.5833],\n",
       "        [0.5556, 0.1250, 0.5763, 0.5000],\n",
       "        [0.3611, 0.4167, 0.5254, 0.5000],\n",
       "        [0.3333, 0.2083, 0.5085, 0.5000],\n",
       "        [0.3333, 0.2500, 0.5763, 0.4583],\n",
       "        [0.5000, 0.4167, 0.6102, 0.5417],\n",
       "        [0.4167, 0.2500, 0.5085, 0.4583],\n",
       "        [0.1944, 0.1250, 0.3898, 0.3750],\n",
       "        [0.3611, 0.2917, 0.5424, 0.5000],\n",
       "        [0.3889, 0.4167, 0.5424, 0.4583],\n",
       "        [0.3889, 0.3750, 0.5424, 0.5000],\n",
       "        [0.5278, 0.3750, 0.5593, 0.5000],\n",
       "        [0.2222, 0.2083, 0.3390, 0.4167],\n",
       "        [0.3889, 0.3333, 0.5254, 0.5000],\n",
       "        [0.5556, 0.5417, 0.8475, 1.0000],\n",
       "        [0.4167, 0.2917, 0.6949, 0.7500],\n",
       "        [0.7778, 0.4167, 0.8305, 0.8333],\n",
       "        [0.5556, 0.3750, 0.7797, 0.7083],\n",
       "        [0.6111, 0.4167, 0.8136, 0.8750],\n",
       "        [0.9167, 0.4167, 0.9492, 0.8333],\n",
       "        [0.1667, 0.2083, 0.5932, 0.6667],\n",
       "        [0.8333, 0.3750, 0.8983, 0.7083],\n",
       "        [0.6667, 0.2083, 0.8136, 0.7083],\n",
       "        [0.8056, 0.6667, 0.8644, 1.0000],\n",
       "        [0.6111, 0.5000, 0.6949, 0.7917],\n",
       "        [0.5833, 0.2917, 0.7288, 0.7500],\n",
       "        [0.6944, 0.4167, 0.7627, 0.8333],\n",
       "        [0.3889, 0.2083, 0.6780, 0.7917],\n",
       "        [0.4167, 0.3333, 0.6949, 0.9583],\n",
       "        [0.5833, 0.5000, 0.7288, 0.9167],\n",
       "        [0.6111, 0.4167, 0.7627, 0.7083],\n",
       "        [0.9444, 0.7500, 0.9661, 0.8750],\n",
       "        [0.9444, 0.2500, 1.0000, 0.9167],\n",
       "        [0.4722, 0.0833, 0.6780, 0.5833],\n",
       "        [0.7222, 0.5000, 0.7966, 0.9167],\n",
       "        [0.3611, 0.3333, 0.6610, 0.7917],\n",
       "        [0.9444, 0.3333, 0.9661, 0.7917],\n",
       "        [0.5556, 0.2917, 0.6610, 0.7083],\n",
       "        [0.6667, 0.5417, 0.7966, 0.8333],\n",
       "        [0.8056, 0.5000, 0.8475, 0.7083],\n",
       "        [0.5278, 0.3333, 0.6441, 0.7083],\n",
       "        [0.5000, 0.4167, 0.6610, 0.7083],\n",
       "        [0.5833, 0.3333, 0.7797, 0.8333],\n",
       "        [0.8056, 0.4167, 0.8136, 0.6250],\n",
       "        [0.8611, 0.3333, 0.8644, 0.7500],\n",
       "        [1.0000, 0.7500, 0.9153, 0.7917],\n",
       "        [0.5833, 0.3333, 0.7797, 0.8750],\n",
       "        [0.5556, 0.3333, 0.6949, 0.5833],\n",
       "        [0.5000, 0.2500, 0.7797, 0.5417],\n",
       "        [0.9444, 0.4167, 0.8644, 0.9167],\n",
       "        [0.5556, 0.5833, 0.7797, 0.9583],\n",
       "        [0.5833, 0.4583, 0.7627, 0.7083],\n",
       "        [0.4722, 0.4167, 0.6441, 0.7083],\n",
       "        [0.7222, 0.4583, 0.7458, 0.8333],\n",
       "        [0.6667, 0.4583, 0.7797, 0.9583],\n",
       "        [0.7222, 0.4583, 0.6949, 0.9167],\n",
       "        [0.4167, 0.2917, 0.6949, 0.7500],\n",
       "        [0.6944, 0.5000, 0.8305, 0.9167],\n",
       "        [0.6667, 0.5417, 0.7966, 1.0000],\n",
       "        [0.6667, 0.4167, 0.7119, 0.9167],\n",
       "        [0.5556, 0.2083, 0.6780, 0.7500],\n",
       "        [0.6111, 0.4167, 0.7119, 0.7917],\n",
       "        [0.5278, 0.5833, 0.7458, 0.9167],\n",
       "        [0.4444, 0.4167, 0.6949, 0.7083]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = torch.tensor(scaler.fit_transform(X)).to(device)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y = torch.tensor(encoder.fit_transform(y.reshape(-1, 1)).toarray()).to(device)\n",
    "\n",
    "display(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([105, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42)\n",
    "\n",
    "display(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 4]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define and Train the MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 3]                   --\n",
       "├─Linear: 1-1                            [32, 16]                  80\n",
       "├─ReLU: 1-2                              [32, 16]                  --\n",
       "├─Linear: 1-3                            [32, 3]                   51\n",
       "├─Softmax: 1-4                           [32, 3]                   --\n",
       "==========================================================================================\n",
       "Total params: 131\n",
       "Trainable params: 131\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 3),\n",
    "    nn.Softmax(dim=1)\n",
    ").to(device)\n",
    "\n",
    "summary(model, input_size=(batch_size, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829735eba09b49a1a2ffb3b88c5cc89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'train_loss': 1.1076380423166685, 'val_loss': 1.1184950669606526}\n",
      "{'epoch': 2, 'train_loss': 1.1024088414592876, 'val_loss': 1.1173643032709757}\n",
      "{'epoch': 3, 'train_loss': 1.0969621324911714, 'val_loss': 1.116293700536092}\n",
      "{'epoch': 4, 'train_loss': 1.1006079782835312, 'val_loss': 1.1157673835754394}\n",
      "{'epoch': 5, 'train_loss': 1.095529809076753, 'val_loss': 1.1151066621144612}\n",
      "{'epoch': 6, 'train_loss': 1.0991388447582722, 'val_loss': 1.114312513669332}\n",
      "{'epoch': 7, 'train_loss': 1.0906403732175627, 'val_loss': 1.1133387009302775}\n",
      "{'epoch': 8, 'train_loss': 1.0887765226264794, 'val_loss': 1.112673004468282}\n",
      "{'epoch': 9, 'train_loss': 1.0960845548866525, 'val_loss': 1.111895457903544}\n",
      "{'epoch': 10, 'train_loss': 1.0995344580668542, 'val_loss': 1.1108688910802205}\n",
      "{'epoch': 11, 'train_loss': 1.0869661095655627, 'val_loss': 1.109644595781962}\n",
      "{'epoch': 12, 'train_loss': 1.088134624167449, 'val_loss': 1.1087634245554605}\n",
      "{'epoch': 13, 'train_loss': 1.0897357675971255, 'val_loss': 1.1079086621602376}\n",
      "{'epoch': 14, 'train_loss': 1.0897423846440182, 'val_loss': 1.1067201137542724}\n",
      "{'epoch': 15, 'train_loss': 1.0862975978913405, 'val_loss': 1.1050604899724323}\n",
      "{'epoch': 16, 'train_loss': 1.0867307564347155, 'val_loss': 1.1033500989278158}\n",
      "{'epoch': 17, 'train_loss': 1.085319698581265, 'val_loss': 1.1016191641489665}\n",
      "{'epoch': 18, 'train_loss': 1.0856244183248944, 'val_loss': 1.099848985671997}\n",
      "{'epoch': 19, 'train_loss': 1.079104033557491, 'val_loss': 1.0979186216990153}\n",
      "{'epoch': 20, 'train_loss': 1.079102612204022, 'val_loss': 1.0963139136632283}\n",
      "{'epoch': 21, 'train_loss': 1.0814947648905218, 'val_loss': 1.0947901964187623}\n",
      "{'epoch': 22, 'train_loss': 1.0749144341486194, 'val_loss': 1.0928971290588378}\n",
      "{'epoch': 23, 'train_loss': 1.0725352006653943, 'val_loss': 1.0910818179448445}\n",
      "{'epoch': 24, 'train_loss': 1.075391947912673, 'val_loss': 1.0893641710281372}\n",
      "{'epoch': 25, 'train_loss': 1.0760570809038148, 'val_loss': 1.0874082724253336}\n",
      "{'epoch': 26, 'train_loss': 1.0688777345025704, 'val_loss': 1.0850024700164795}\n",
      "{'epoch': 27, 'train_loss': 1.0719092878409557, 'val_loss': 1.0825174649556477}\n",
      "{'epoch': 28, 'train_loss': 1.0653401463189058, 'val_loss': 1.0799025297164917}\n",
      "{'epoch': 29, 'train_loss': 1.0649473564699292, 'val_loss': 1.0775629520416259}\n",
      "{'epoch': 30, 'train_loss': 1.0633664260514908, 'val_loss': 1.0752306540807088}\n",
      "{'epoch': 31, 'train_loss': 1.0586136372552977, 'val_loss': 1.0730701684951782}\n",
      "{'epoch': 32, 'train_loss': 1.0592588096236188, 'val_loss': 1.0711927890777588}\n",
      "{'epoch': 33, 'train_loss': 1.0603133312736948, 'val_loss': 1.0691563685735066}\n",
      "{'epoch': 34, 'train_loss': 1.0586982790587678, 'val_loss': 1.0663752158482869}\n",
      "{'epoch': 35, 'train_loss': 1.0559797642442086, 'val_loss': 1.063310964902242}\n",
      "{'epoch': 36, 'train_loss': 1.055549834130539, 'val_loss': 1.059803827603658}\n",
      "{'epoch': 37, 'train_loss': 1.0499162622210052, 'val_loss': 1.0559378782908122}\n",
      "{'epoch': 38, 'train_loss': 1.047592877306872, 'val_loss': 1.0522785107294719}\n",
      "{'epoch': 39, 'train_loss': 1.0444550942629576, 'val_loss': 1.0490383625030517}\n",
      "{'epoch': 40, 'train_loss': 1.0427930757610335, 'val_loss': 1.0455256700515747}\n",
      "{'epoch': 41, 'train_loss': 1.0398551283611193, 'val_loss': 1.0416258335113526}\n",
      "{'epoch': 42, 'train_loss': 1.0404800890117056, 'val_loss': 1.037283976872762}\n",
      "{'epoch': 43, 'train_loss': 1.0355625095673733, 'val_loss': 1.0333898107210795}\n",
      "{'epoch': 44, 'train_loss': 1.0342804404596486, 'val_loss': 1.029222818215688}\n",
      "{'epoch': 45, 'train_loss': 1.0304422596883442, 'val_loss': 1.024290684858958}\n",
      "{'epoch': 46, 'train_loss': 1.0280291210446093, 'val_loss': 1.019621237119039}\n",
      "{'epoch': 47, 'train_loss': 1.0262291113742523, 'val_loss': 1.0151204387346904}\n",
      "{'epoch': 48, 'train_loss': 1.0213646298377879, 'val_loss': 1.0108582496643066}\n",
      "{'epoch': 49, 'train_loss': 1.017414411322938, 'val_loss': 1.006250540415446}\n",
      "{'epoch': 50, 'train_loss': 1.0142096038390365, 'val_loss': 1.0010428547859191}\n",
      "{'epoch': 51, 'train_loss': 1.0128538500414126, 'val_loss': 0.9956480264663696}\n",
      "{'epoch': 52, 'train_loss': 1.006807135676758, 'val_loss': 0.9906982858975728}\n",
      "{'epoch': 53, 'train_loss': 1.006802560761571, 'val_loss': 0.9849242806434632}\n",
      "{'epoch': 54, 'train_loss': 1.0036251735356119, 'val_loss': 0.9793589313824972}\n",
      "{'epoch': 55, 'train_loss': 1.0023648974796135, 'val_loss': 0.9739401419957479}\n",
      "{'epoch': 56, 'train_loss': 0.9957146226014528, 'val_loss': 0.9688080430030822}\n",
      "{'epoch': 57, 'train_loss': 0.99301257248347, 'val_loss': 0.9634774327278137}\n",
      "{'epoch': 58, 'train_loss': 0.9897681310669415, 'val_loss': 0.95795206228892}\n",
      "{'epoch': 59, 'train_loss': 0.9817412703091072, 'val_loss': 0.9524617830912272}\n",
      "{'epoch': 60, 'train_loss': 0.9803610819184946, 'val_loss': 0.9462146480878194}\n",
      "{'epoch': 61, 'train_loss': 0.9801732792208592, 'val_loss': 0.9403436422348023}\n",
      "{'epoch': 62, 'train_loss': 0.9756219215277169, 'val_loss': 0.9343090136845906}\n",
      "{'epoch': 63, 'train_loss': 0.964962996283753, 'val_loss': 0.9285593469937642}\n",
      "{'epoch': 64, 'train_loss': 0.9595514196488593, 'val_loss': 0.9222812175750732}\n",
      "{'epoch': 65, 'train_loss': 0.9613102627400723, 'val_loss': 0.9154510696729025}\n",
      "{'epoch': 66, 'train_loss': 0.9686665165031122, 'val_loss': 0.909359323978424}\n",
      "{'epoch': 67, 'train_loss': 0.9535035435110331, 'val_loss': 0.9041885455449422}\n",
      "{'epoch': 68, 'train_loss': 0.9490024026793737, 'val_loss': 0.8987974206606547}\n",
      "{'epoch': 69, 'train_loss': 0.9388386749972899, 'val_loss': 0.8932696302731832}\n",
      "{'epoch': 70, 'train_loss': 0.93616416098343, 'val_loss': 0.8875760038693746}\n",
      "{'epoch': 71, 'train_loss': 0.9487206702534523, 'val_loss': 0.8817439317703247}\n",
      "{'epoch': 72, 'train_loss': 0.92873562577491, 'val_loss': 0.8762644767761231}\n",
      "{'epoch': 73, 'train_loss': 0.933772970094449, 'val_loss': 0.8708620508511861}\n",
      "{'epoch': 74, 'train_loss': 0.926467781006876, 'val_loss': 0.8657336632410685}\n",
      "{'epoch': 75, 'train_loss': 0.9229128897293575, 'val_loss': 0.8605721433957417}\n",
      "{'epoch': 76, 'train_loss': 0.9300108704612486, 'val_loss': 0.8555563410123189}\n",
      "{'epoch': 77, 'train_loss': 0.9113606706054674, 'val_loss': 0.8507081230481466}\n",
      "{'epoch': 78, 'train_loss': 0.919260885928654, 'val_loss': 0.845499050617218}\n",
      "{'epoch': 79, 'train_loss': 0.923841956951138, 'val_loss': 0.8404125213623047}\n",
      "{'epoch': 80, 'train_loss': 0.8980558485620551, 'val_loss': 0.8358121037483215}\n",
      "{'epoch': 81, 'train_loss': 0.8988241838912169, 'val_loss': 0.8312652150789896}\n",
      "{'epoch': 82, 'train_loss': 0.906810064955304, 'val_loss': 0.8266240040461222}\n",
      "{'epoch': 83, 'train_loss': 0.9150382452644408, 'val_loss': 0.8222402413686116}\n",
      "{'epoch': 84, 'train_loss': 0.8879989093273051, 'val_loss': 0.8185518423716227}\n",
      "{'epoch': 85, 'train_loss': 0.8875762732802994, 'val_loss': 0.8147540807723999}\n",
      "{'epoch': 86, 'train_loss': 0.8999207642239828, 'val_loss': 0.8106831510861715}\n",
      "{'epoch': 87, 'train_loss': 0.8678517756569717, 'val_loss': 0.8069484313329061}\n",
      "{'epoch': 88, 'train_loss': 0.8927478888072073, 'val_loss': 0.8029315590858459}\n",
      "{'epoch': 89, 'train_loss': 0.8796922273209525, 'val_loss': 0.7992166519165039}\n",
      "{'epoch': 90, 'train_loss': 0.8921453281719651, 'val_loss': 0.7959246516227723}\n",
      "{'epoch': 91, 'train_loss': 0.8761759738748272, 'val_loss': 0.7932259360949199}\n",
      "{'epoch': 92, 'train_loss': 0.9046160543544425, 'val_loss': 0.7905246178309122}\n",
      "{'epoch': 93, 'train_loss': 0.8680453841160569, 'val_loss': 0.7887403647104899}\n",
      "{'epoch': 94, 'train_loss': 0.8593466394684381, 'val_loss': 0.786588438351949}\n",
      "{'epoch': 95, 'train_loss': 0.8675185938158797, 'val_loss': 0.7841192801793416}\n",
      "{'epoch': 96, 'train_loss': 0.8745153956632647, 'val_loss': 0.7812322497367858}\n",
      "{'epoch': 97, 'train_loss': 0.8715495439246297, 'val_loss': 0.7784517884254456}\n",
      "{'epoch': 98, 'train_loss': 0.8753371052443981, 'val_loss': 0.7760329246520996}\n",
      "{'epoch': 99, 'train_loss': 0.8606158801250987, 'val_loss': 0.7738865772883097}\n",
      "{'epoch': 100, 'train_loss': 0.8705084852667319, 'val_loss': 0.7717279911041259}\n",
      "{'epoch': 101, 'train_loss': 0.863819603032122, 'val_loss': 0.769681187470754}\n",
      "{'epoch': 102, 'train_loss': 0.8401844428541759, 'val_loss': 0.7677940885225931}\n",
      "{'epoch': 103, 'train_loss': 0.8532116461234788, 'val_loss': 0.765316657225291}\n",
      "{'epoch': 104, 'train_loss': 0.8485934318871133, 'val_loss': 0.7630802671114604}\n",
      "{'epoch': 105, 'train_loss': 0.8519827165744371, 'val_loss': 0.7608118613560995}\n",
      "{'epoch': 106, 'train_loss': 0.8554054591287341, 'val_loss': 0.759017542997996}\n",
      "{'epoch': 107, 'train_loss': 0.857818000122077, 'val_loss': 0.7575477202733357}\n",
      "{'epoch': 108, 'train_loss': 0.8722658408288326, 'val_loss': 0.7562848726908366}\n",
      "{'epoch': 109, 'train_loss': 0.8540131947439578, 'val_loss': 0.7558379968007406}\n",
      "{'epoch': 110, 'train_loss': 0.8660367094497714, 'val_loss': 0.755371089776357}\n",
      "{'epoch': 111, 'train_loss': 0.8309928271402087, 'val_loss': 0.7547452727953593}\n",
      "{'epoch': 112, 'train_loss': 0.8410948414045075, 'val_loss': 0.7540244340896607}\n",
      "{'epoch': 113, 'train_loss': 0.8368126491809057, 'val_loss': 0.7534525076548259}\n",
      "{'epoch': 114, 'train_loss': 0.8378920433008008, 'val_loss': 0.7525905013084412}\n",
      "{'epoch': 115, 'train_loss': 0.8569245546435316, 'val_loss': 0.751403526465098}\n",
      "{'epoch': 116, 'train_loss': 0.8367423872049484, 'val_loss': 0.7510870019594829}\n",
      "{'epoch': 117, 'train_loss': 0.83921145213147, 'val_loss': 0.7506091117858886}\n",
      "{'epoch': 118, 'train_loss': 0.8314647155089511, 'val_loss': 0.7496513366699219}\n",
      "{'epoch': 119, 'train_loss': 0.8337449355878763, 'val_loss': 0.7482142647107443}\n",
      "{'epoch': 120, 'train_loss': 0.8244644883606169, 'val_loss': 0.7466818531354268}\n",
      "{'epoch': 121, 'train_loss': 0.8045043759047985, 'val_loss': 0.7446003198623657}\n",
      "{'epoch': 122, 'train_loss': 0.8210206519191463, 'val_loss': 0.7424231568972269}\n",
      "{'epoch': 123, 'train_loss': 0.8249537147478097, 'val_loss': 0.7402939597765604}\n",
      "{'epoch': 124, 'train_loss': 0.8443480221968558, 'val_loss': 0.7384925484657288}\n",
      "{'epoch': 125, 'train_loss': 0.8246107998097109, 'val_loss': 0.7381017923355102}\n",
      "{'epoch': 126, 'train_loss': 0.8187655950896442, 'val_loss': 0.7373861233393351}\n",
      "{'epoch': 127, 'train_loss': 0.8211747355138261, 'val_loss': 0.7367766777674357}\n",
      "{'epoch': 128, 'train_loss': 0.8092881208803091, 'val_loss': 0.7358898321787516}\n",
      "{'epoch': 129, 'train_loss': 0.8263748257110516, 'val_loss': 0.7346720655759176}\n",
      "{'epoch': 130, 'train_loss': 0.8044616943742666, 'val_loss': 0.7339379111925761}\n",
      "{'epoch': 131, 'train_loss': 0.8146667437007029, 'val_loss': 0.7321606516838074}\n",
      "{'epoch': 132, 'train_loss': 0.8377663113383783, 'val_loss': 0.7305179556210836}\n",
      "{'epoch': 133, 'train_loss': 0.8312181181584795, 'val_loss': 0.7301390329996744}\n",
      "{'epoch': 134, 'train_loss': 0.8112700324402087, 'val_loss': 0.7299725015958151}\n",
      "{'epoch': 135, 'train_loss': 0.7982032754355006, 'val_loss': 0.7296288887659709}\n",
      "{'epoch': 136, 'train_loss': 0.7855837490513093, 'val_loss': 0.7288641413052876}\n",
      "{'epoch': 137, 'train_loss': 0.7914515000561045, 'val_loss': 0.7272845188776652}\n",
      "{'epoch': 138, 'train_loss': 0.8180691656242642, 'val_loss': 0.7256722211837768}\n",
      "{'epoch': 139, 'train_loss': 0.8028986304998398, 'val_loss': 0.7247891982396444}\n",
      "{'epoch': 140, 'train_loss': 0.802702927030623, 'val_loss': 0.7246981382369995}\n",
      "{'epoch': 141, 'train_loss': 0.8126674898279209, 'val_loss': 0.724505869547526}\n",
      "{'epoch': 142, 'train_loss': 0.7895910654010044, 'val_loss': 0.7242783824602763}\n",
      "{'epoch': 143, 'train_loss': 0.811782273515645, 'val_loss': 0.7229502916336059}\n",
      "{'epoch': 144, 'train_loss': 0.7893633116554055, 'val_loss': 0.7225695490837097}\n",
      "{'epoch': 145, 'train_loss': 0.7859560932136245, 'val_loss': 0.7219568848609924}\n",
      "{'epoch': 146, 'train_loss': 0.7975146470384465, 'val_loss': 0.7214187900225322}\n",
      "{'epoch': 147, 'train_loss': 0.8081089182135959, 'val_loss': 0.7210985779762268}\n",
      "{'epoch': 148, 'train_loss': 0.7911739981629782, 'val_loss': 0.7215670108795166}\n",
      "{'epoch': 149, 'train_loss': 0.7975914355160462, 'val_loss': 0.7214549422264099}\n",
      "{'epoch': 150, 'train_loss': 0.7945020409921805, 'val_loss': 0.7205447196960449}\n",
      "{'epoch': 151, 'train_loss': 0.7706257055720521, 'val_loss': 0.7192567348480224}\n",
      "{'epoch': 152, 'train_loss': 0.7832478265691962, 'val_loss': 0.717293361822764}\n",
      "{'epoch': 153, 'train_loss': 0.79693736994846, 'val_loss': 0.716334327061971}\n",
      "{'epoch': 154, 'train_loss': 0.7838148907758296, 'val_loss': 0.7160660664240519}\n",
      "{'epoch': 155, 'train_loss': 0.8012423982015915, 'val_loss': 0.7146602352460225}\n",
      "{'epoch': 156, 'train_loss': 0.7865242354261378, 'val_loss': 0.7132630546887716}\n",
      "{'epoch': 157, 'train_loss': 0.7864557426008913, 'val_loss': 0.7117676496505737}\n",
      "{'epoch': 158, 'train_loss': 0.7974167068281935, 'val_loss': 0.7106635252634684}\n",
      "{'epoch': 159, 'train_loss': 0.7769955720028116, 'val_loss': 0.7100548148155212}\n",
      "{'epoch': 160, 'train_loss': 0.7836791736384232, 'val_loss': 0.7098775068918863}\n",
      "{'epoch': 161, 'train_loss': 0.7818343196995556, 'val_loss': 0.7097165862719218}\n",
      "{'epoch': 162, 'train_loss': 0.786658054528137, 'val_loss': 0.7096207459767659}\n",
      "{'epoch': 163, 'train_loss': 0.786021365887589, 'val_loss': 0.7096964796384175}\n",
      "{'epoch': 164, 'train_loss': 0.7904625585716631, 'val_loss': 0.7099290251731872}\n",
      "{'epoch': 165, 'train_loss': 0.7824751307360001, 'val_loss': 0.7105697671572367}\n",
      "{'epoch': 166, 'train_loss': 0.7671608929004934, 'val_loss': 0.7112410426139831}\n",
      "{'epoch': 167, 'train_loss': 0.7765025878842506, 'val_loss': 0.7108399152755738}\n",
      "{'epoch': 168, 'train_loss': 0.7824055401401387, 'val_loss': 0.7107471942901611}\n",
      "{'epoch': 169, 'train_loss': 0.7700650578157769, 'val_loss': 0.7107027570406595}\n",
      "{'epoch': 170, 'train_loss': 0.7769361503111819, 'val_loss': 0.7100621541341146}\n",
      "{'epoch': 171, 'train_loss': 0.7660217220998473, 'val_loss': 0.7090104381243387}\n",
      "{'epoch': 172, 'train_loss': 0.7760996362194419, 'val_loss': 0.7078600446383159}\n",
      "{'epoch': 173, 'train_loss': 0.7690217051034172, 'val_loss': 0.707123319307963}\n",
      "{'epoch': 174, 'train_loss': 0.7838459557129277, 'val_loss': 0.7055539011955261}\n",
      "{'epoch': 175, 'train_loss': 0.7664058510628011, 'val_loss': 0.7041816353797913}\n",
      "{'epoch': 176, 'train_loss': 0.7762564041444825, 'val_loss': 0.7032020131746928}\n",
      "{'epoch': 177, 'train_loss': 0.7685274879137675, 'val_loss': 0.7025494138399759}\n",
      "{'epoch': 178, 'train_loss': 0.7611311824681858, 'val_loss': 0.7023698012034099}\n",
      "{'epoch': 179, 'train_loss': 0.7684718084832032, 'val_loss': 0.7022255539894104}\n",
      "{'epoch': 180, 'train_loss': 0.7694890860778589, 'val_loss': 0.7028813640276591}\n",
      "{'epoch': 181, 'train_loss': 0.773679163151731, 'val_loss': 0.7033819754918417}\n",
      "{'epoch': 182, 'train_loss': 0.7613078207812376, 'val_loss': 0.7038476308186848}\n",
      "{'epoch': 183, 'train_loss': 0.7582128492908345, 'val_loss': 0.7028992891311645}\n",
      "{'epoch': 184, 'train_loss': 0.7553672215176953, 'val_loss': 0.7025334715843201}\n",
      "{'epoch': 185, 'train_loss': 0.7551203363368081, 'val_loss': 0.7027973016103108}\n",
      "{'epoch': 186, 'train_loss': 0.7610445595863793, 'val_loss': 0.702093247572581}\n",
      "{'epoch': 187, 'train_loss': 0.7579945517807372, 'val_loss': 0.7016445279121399}\n",
      "{'epoch': 188, 'train_loss': 0.765341061891781, 'val_loss': 0.7002874811490377}\n",
      "{'epoch': 189, 'train_loss': 0.7493958830729954, 'val_loss': 0.6979299704233806}\n",
      "{'epoch': 190, 'train_loss': 0.7524018216774695, 'val_loss': 0.6953057845433553}\n",
      "{'epoch': 191, 'train_loss': 0.7482961427109937, 'val_loss': 0.6935550888379415}\n",
      "{'epoch': 192, 'train_loss': 0.7616314128455188, 'val_loss': 0.6923277576764425}\n",
      "{'epoch': 193, 'train_loss': 0.7607789763973819, 'val_loss': 0.6925512870152791}\n",
      "{'epoch': 194, 'train_loss': 0.7538322332418628, 'val_loss': 0.6924840807914734}\n",
      "{'epoch': 195, 'train_loss': 0.7465402684174478, 'val_loss': 0.6920344670613606}\n",
      "{'epoch': 196, 'train_loss': 0.7441876413714554, 'val_loss': 0.691634996732076}\n",
      "{'epoch': 197, 'train_loss': 0.7396958945836458, 'val_loss': 0.6905486742655436}\n",
      "{'epoch': 198, 'train_loss': 0.7573999288077984, 'val_loss': 0.6892269055048624}\n",
      "{'epoch': 199, 'train_loss': 0.741455983215322, 'val_loss': 0.688898253440857}\n",
      "{'epoch': 200, 'train_loss': 0.7541118745899035, 'val_loss': 0.6878070155779521}\n",
      "{'epoch': 201, 'train_loss': 0.7455140351731744, 'val_loss': 0.688123369216919}\n",
      "{'epoch': 202, 'train_loss': 0.72960590540121, 'val_loss': 0.6888333996136983}\n",
      "{'epoch': 203, 'train_loss': 0.7410180691319207, 'val_loss': 0.6885766307512919}\n",
      "{'epoch': 204, 'train_loss': 0.7476445984923177, 'val_loss': 0.6887720823287964}\n",
      "{'epoch': 205, 'train_loss': 0.744073476901071, 'val_loss': 0.6892726143201192}\n",
      "{'epoch': 206, 'train_loss': 0.7307826623113619, 'val_loss': 0.6896224459012349}\n",
      "{'epoch': 207, 'train_loss': 0.7430978365139, 'val_loss': 0.6889243404070536}\n",
      "{'epoch': 208, 'train_loss': 0.7417938796699874, 'val_loss': 0.6868011991182963}\n",
      "{'epoch': 209, 'train_loss': 0.7297749886185758, 'val_loss': 0.6851771513621012}\n",
      "{'epoch': 210, 'train_loss': 0.7383036839051379, 'val_loss': 0.6835078557332357}\n",
      "{'epoch': 211, 'train_loss': 0.746204122280081, 'val_loss': 0.6821964820226033}\n",
      "{'epoch': 212, 'train_loss': 0.741766706885149, 'val_loss': 0.681055478254954}\n",
      "{'epoch': 213, 'train_loss': 0.7302353447820578, 'val_loss': 0.6798495093981425}\n",
      "{'epoch': 214, 'train_loss': 0.7238344925248789, 'val_loss': 0.6780054171880087}\n",
      "{'epoch': 215, 'train_loss': 0.7398595652129087, 'val_loss': 0.6767871896425883}\n",
      "{'epoch': 216, 'train_loss': 0.7275583529327478, 'val_loss': 0.6761853098869324}\n",
      "{'epoch': 217, 'train_loss': 0.7302257460542023, 'val_loss': 0.6757686336835226}\n",
      "{'epoch': 218, 'train_loss': 0.7377112096485992, 'val_loss': 0.6764974792798361}\n",
      "{'epoch': 219, 'train_loss': 0.7328187689288623, 'val_loss': 0.6772487998008728}\n",
      "{'epoch': 220, 'train_loss': 0.7233875040999718, 'val_loss': 0.6778732339541117}\n",
      "{'epoch': 221, 'train_loss': 0.7236729185614321, 'val_loss': 0.6778388341267904}\n",
      "{'epoch': 222, 'train_loss': 0.7135705300606787, 'val_loss': 0.6771810293197632}\n",
      "{'epoch': 223, 'train_loss': 0.7233050330024626, 'val_loss': 0.6767106016476949}\n",
      "{'epoch': 224, 'train_loss': 0.7229580146571, 'val_loss': 0.6767567078272502}\n",
      "{'epoch': 225, 'train_loss': 0.7261199357195033, 'val_loss': 0.6770803372065226}\n",
      "{'epoch': 226, 'train_loss': 0.7302606547665265, 'val_loss': 0.6767660140991211}\n",
      "{'epoch': 227, 'train_loss': 0.718656421949466, 'val_loss': 0.6752900083859762}\n",
      "{'epoch': 228, 'train_loss': 0.7127076903254621, 'val_loss': 0.6743998209635417}\n",
      "{'epoch': 229, 'train_loss': 0.7213784111663699, 'val_loss': 0.6734549522399902}\n",
      "{'epoch': 230, 'train_loss': 0.7239950296675993, 'val_loss': 0.6713850895563761}\n",
      "{'epoch': 231, 'train_loss': 0.7251508601216806, 'val_loss': 0.6710734923680624}\n",
      "{'epoch': 232, 'train_loss': 0.7225180420403678, 'val_loss': 0.6703848361968994}\n",
      "{'epoch': 233, 'train_loss': 0.7298369231219921, 'val_loss': 0.6708714723587036}\n",
      "{'epoch': 234, 'train_loss': 0.706023807482173, 'val_loss': 0.6711211005846659}\n",
      "{'epoch': 235, 'train_loss': 0.729915347829875, 'val_loss': 0.6720014532407125}\n",
      "{'epoch': 236, 'train_loss': 0.7209739298559725, 'val_loss': 0.6728602011998495}\n",
      "{'epoch': 237, 'train_loss': 0.7152189656367732, 'val_loss': 0.6732147336006165}\n",
      "{'epoch': 238, 'train_loss': 0.7117435147778856, 'val_loss': 0.6734634876251221}\n",
      "{'epoch': 239, 'train_loss': 0.7127819182351232, 'val_loss': 0.6731982787450155}\n",
      "{'epoch': 240, 'train_loss': 0.7197207167951597, 'val_loss': 0.6723768790562947}\n",
      "{'epoch': 241, 'train_loss': 0.7168828882277012, 'val_loss': 0.6705300450325012}\n",
      "{'epoch': 242, 'train_loss': 0.7130832007258303, 'val_loss': 0.6687111695607503}\n",
      "{'epoch': 243, 'train_loss': 0.7011830364871356, 'val_loss': 0.6673111716906229}\n",
      "{'epoch': 244, 'train_loss': 0.7083231098432508, 'val_loss': 0.6662972092628479}\n",
      "{'epoch': 245, 'train_loss': 0.7037031460139487, 'val_loss': 0.6654319246610005}\n",
      "{'epoch': 246, 'train_loss': 0.715484452382144, 'val_loss': 0.6647094408671061}\n",
      "{'epoch': 247, 'train_loss': 0.7099217223520908, 'val_loss': 0.6636756738026937}\n",
      "{'epoch': 248, 'train_loss': 0.7125246161594987, 'val_loss': 0.6633272528648376}\n",
      "{'epoch': 249, 'train_loss': 0.7078983417401711, 'val_loss': 0.6637977004051209}\n",
      "{'epoch': 250, 'train_loss': 0.7087638224475086, 'val_loss': 0.664616326491038}\n",
      "{'epoch': 251, 'train_loss': 0.6998507759223381, 'val_loss': 0.6650622646013895}\n",
      "{'epoch': 252, 'train_loss': 0.7047563279047608, 'val_loss': 0.66453564564387}\n",
      "{'epoch': 253, 'train_loss': 0.7073374552031357, 'val_loss': 0.6644804835319519}\n",
      "{'epoch': 254, 'train_loss': 0.709532408716364, 'val_loss': 0.6647478183110554}\n",
      "{'epoch': 255, 'train_loss': 0.6921099881745048, 'val_loss': 0.6651851812998454}\n",
      "{'epoch': 256, 'train_loss': 0.701831319835037, 'val_loss': 0.6644068400065104}\n",
      "{'epoch': 257, 'train_loss': 0.7040457330747611, 'val_loss': 0.6630583643913269}\n",
      "{'epoch': 258, 'train_loss': 0.7097043812585373, 'val_loss': 0.6613582571347555}\n",
      "{'epoch': 259, 'train_loss': 0.7045247606001794, 'val_loss': 0.6592821081479391}\n",
      "{'epoch': 260, 'train_loss': 0.7014243241606487, 'val_loss': 0.6574424227078756}\n",
      "{'epoch': 261, 'train_loss': 0.6899375080441434, 'val_loss': 0.656074607372284}\n",
      "{'epoch': 262, 'train_loss': 0.6981313922442496, 'val_loss': 0.6553015192349751}\n",
      "{'epoch': 263, 'train_loss': 0.6934433616697788, 'val_loss': 0.654951274394989}\n",
      "{'epoch': 264, 'train_loss': 0.6920892713177536, 'val_loss': 0.6540984670321146}\n",
      "{'epoch': 265, 'train_loss': 0.6886095335293148, 'val_loss': 0.6532506028811137}\n",
      "{'epoch': 266, 'train_loss': 0.7061471442381541, 'val_loss': 0.6529673933982849}\n",
      "{'epoch': 267, 'train_loss': 0.7025678892516427, 'val_loss': 0.6531853000322978}\n",
      "{'epoch': 268, 'train_loss': 0.7150192766243385, 'val_loss': 0.6531336983044942}\n",
      "{'epoch': 269, 'train_loss': 0.7020552768371999, 'val_loss': 0.6543959975242615}\n",
      "{'epoch': 270, 'train_loss': 0.7038587988871667, 'val_loss': 0.6555471857388814}\n",
      "{'epoch': 271, 'train_loss': 0.698986943759438, 'val_loss': 0.655996827284495}\n",
      "{'epoch': 272, 'train_loss': 0.7096184674753911, 'val_loss': 0.6568457166353862}\n",
      "{'epoch': 273, 'train_loss': 0.6913140689850681, 'val_loss': 0.6570294857025146}\n",
      "{'epoch': 274, 'train_loss': 0.6853719563223422, 'val_loss': 0.6569167097409566}\n",
      "{'epoch': 275, 'train_loss': 0.6881556361913681, 'val_loss': 0.6562825004259745}\n",
      "{'epoch': 276, 'train_loss': 0.7052572106218172, 'val_loss': 0.6551283836364746}\n",
      "{'epoch': 277, 'train_loss': 0.6969608910278313, 'val_loss': 0.6535037954648336}\n",
      "{'epoch': 278, 'train_loss': 0.6896840894801749, 'val_loss': 0.6524704853693644}\n",
      "{'epoch': 279, 'train_loss': 0.7012533508758578, 'val_loss': 0.6524581551551819}\n",
      "{'epoch': 280, 'train_loss': 0.6822158703580499, 'val_loss': 0.6516347924868265}\n",
      "{'epoch': 281, 'train_loss': 0.6851695349129537, 'val_loss': 0.6511436502138773}\n",
      "{'epoch': 282, 'train_loss': 0.6946032275963161, 'val_loss': 0.6503770351409912}\n",
      "{'epoch': 283, 'train_loss': 0.6899968996230099, 'val_loss': 0.6492390950520833}\n",
      "{'epoch': 284, 'train_loss': 0.6787375225168135, 'val_loss': 0.6481612881024679}\n",
      "{'epoch': 285, 'train_loss': 0.6862533804443147, 'val_loss': 0.6476364056269328}\n",
      "{'epoch': 286, 'train_loss': 0.678919375460181, 'val_loss': 0.6476102352142334}\n",
      "{'epoch': 287, 'train_loss': 0.6916701746069722, 'val_loss': 0.6480615297953287}\n",
      "{'epoch': 288, 'train_loss': 0.6828414175866379, 'val_loss': 0.6474485794703165}\n",
      "{'epoch': 289, 'train_loss': 0.6877236135510935, 'val_loss': 0.646425986289978}\n",
      "{'epoch': 290, 'train_loss': 0.6880565945886903, 'val_loss': 0.6457456747690836}\n",
      "{'epoch': 291, 'train_loss': 0.6839574299649231, 'val_loss': 0.6462511618932089}\n",
      "{'epoch': 292, 'train_loss': 0.6679422573910819, 'val_loss': 0.6472428798675537}\n",
      "{'epoch': 293, 'train_loss': 0.6826314080713524, 'val_loss': 0.6473583658536275}\n",
      "{'epoch': 294, 'train_loss': 0.675161219564163, 'val_loss': 0.6476610740025838}\n",
      "{'epoch': 295, 'train_loss': 0.6885541239235964, 'val_loss': 0.6477831761042276}\n",
      "{'epoch': 296, 'train_loss': 0.6809852035302255, 'val_loss': 0.6472484946250916}\n",
      "{'epoch': 297, 'train_loss': 0.6886677077143557, 'val_loss': 0.6459374308586121}\n",
      "{'epoch': 298, 'train_loss': 0.6700888870594401, 'val_loss': 0.6444249669710795}\n",
      "{'epoch': 299, 'train_loss': 0.6769969611325197, 'val_loss': 0.642965809504191}\n",
      "{'epoch': 300, 'train_loss': 0.6818257091670401, 'val_loss': 0.6413386702537537}\n",
      "{'epoch': 301, 'train_loss': 0.6846639019333653, 'val_loss': 0.6407079418500264}\n",
      "{'epoch': 302, 'train_loss': 0.6860372921865847, 'val_loss': 0.6398865977923075}\n",
      "{'epoch': 303, 'train_loss': 0.6839300830227633, 'val_loss': 0.6394640485445658}\n",
      "{'epoch': 304, 'train_loss': 0.6858338977520664, 'val_loss': 0.6381660858790079}\n",
      "{'epoch': 305, 'train_loss': 0.6712334796061946, 'val_loss': 0.6378885348637898}\n",
      "{'epoch': 306, 'train_loss': 0.6776932808053162, 'val_loss': 0.6378056089083354}\n",
      "{'epoch': 307, 'train_loss': 0.67150410099162, 'val_loss': 0.6378750562667846}\n",
      "{'epoch': 308, 'train_loss': 0.6691508053594993, 'val_loss': 0.6375771681467692}\n",
      "{'epoch': 309, 'train_loss': 0.6759145486996405, 'val_loss': 0.6374338706334431}\n",
      "{'epoch': 310, 'train_loss': 0.6934499810967181, 'val_loss': 0.6374027967453003}\n",
      "{'epoch': 311, 'train_loss': 0.6728435091984768, 'val_loss': 0.6377397259076436}\n",
      "{'epoch': 312, 'train_loss': 0.6738473658139507, 'val_loss': 0.6377442876497904}\n",
      "{'epoch': 313, 'train_loss': 0.6775132154838907, 'val_loss': 0.6381035526593526}\n",
      "{'epoch': 314, 'train_loss': 0.6712456808115045, 'val_loss': 0.6381768425305684}\n",
      "{'epoch': 315, 'train_loss': 0.6668530338340335, 'val_loss': 0.6388491829236348}\n",
      "{'epoch': 316, 'train_loss': 0.6780657211008171, 'val_loss': 0.6389841636021932}\n",
      "{'epoch': 317, 'train_loss': 0.6739549713416232, 'val_loss': 0.637813138961792}\n",
      "{'epoch': 318, 'train_loss': 0.6645425679679546, 'val_loss': 0.6368386705716451}\n",
      "{'epoch': 319, 'train_loss': 0.6675786597447263, 'val_loss': 0.6358201344807942}\n",
      "{'epoch': 320, 'train_loss': 0.6782995096614791, 'val_loss': 0.6353346546490987}\n",
      "{'epoch': 321, 'train_loss': 0.6662476301814119, 'val_loss': 0.6352341810862223}\n",
      "{'epoch': 322, 'train_loss': 0.6657102456730273, 'val_loss': 0.6355091094970703}\n",
      "{'epoch': 323, 'train_loss': 0.6739206708346803, 'val_loss': 0.6350592136383056}\n",
      "{'epoch': 324, 'train_loss': 0.6827194425794814, 'val_loss': 0.6348806619644165}\n",
      "{'epoch': 325, 'train_loss': 0.6684604828349419, 'val_loss': 0.6361168225606283}\n",
      "{'epoch': 326, 'train_loss': 0.673172844056454, 'val_loss': 0.6370921055475871}\n",
      "{'epoch': 327, 'train_loss': 0.6684188738258349, 'val_loss': 0.6380695144335429}\n",
      "{'epoch': 328, 'train_loss': 0.6640954499339892, 'val_loss': 0.6380615393320719}\n",
      "{'epoch': 329, 'train_loss': 0.6622435812734895, 'val_loss': 0.6382172187169393}\n",
      "{'epoch': 330, 'train_loss': 0.6648010759510927, 'val_loss': 0.6384914000829061}\n",
      "{'epoch': 331, 'train_loss': 0.6748995895807941, 'val_loss': 0.6378019571304321}\n",
      "{'epoch': 332, 'train_loss': 0.6843830743390653, 'val_loss': 0.636968195438385}\n",
      "{'epoch': 333, 'train_loss': 0.6757871160387166, 'val_loss': 0.6359570145606994}\n",
      "{'epoch': 334, 'train_loss': 0.6647300335268179, 'val_loss': 0.6347953677177429}\n",
      "{'epoch': 335, 'train_loss': 0.6633849214348528, 'val_loss': 0.6334347208340962}\n",
      "{'epoch': 336, 'train_loss': 0.6623985648879575, 'val_loss': 0.6328280806541443}\n",
      "{'epoch': 337, 'train_loss': 0.6750035961675975, 'val_loss': 0.6317126353581747}\n",
      "{'epoch': 338, 'train_loss': 0.6650996681613226, 'val_loss': 0.6314813494682312}\n",
      "{'epoch': 339, 'train_loss': 0.6677526124856539, 'val_loss': 0.6314381082852681}\n",
      "{'epoch': 340, 'train_loss': 0.6732913024413089, 'val_loss': 0.6317235271135966}\n",
      "{'epoch': 341, 'train_loss': 0.6644006400472589, 'val_loss': 0.6317198038101196}\n",
      "{'epoch': 342, 'train_loss': 0.6641080674922301, 'val_loss': 0.6315982699394226}\n",
      "{'epoch': 343, 'train_loss': 0.6584660805658333, 'val_loss': 0.6306593656539917}\n",
      "{'epoch': 344, 'train_loss': 0.681675857036478, 'val_loss': 0.6298623601595561}\n",
      "{'epoch': 345, 'train_loss': 0.6528287480792238, 'val_loss': 0.6289757053057352}\n",
      "{'epoch': 346, 'train_loss': 0.6721733176252909, 'val_loss': 0.6287838419278463}\n",
      "{'epoch': 347, 'train_loss': 0.67535586686184, 'val_loss': 0.628873606522878}\n",
      "{'epoch': 348, 'train_loss': 0.6677701717449559, 'val_loss': 0.6286533832550049}\n",
      "{'epoch': 349, 'train_loss': 0.6509572198200557, 'val_loss': 0.6286882082621257}\n",
      "{'epoch': 350, 'train_loss': 0.67459697695449, 'val_loss': 0.6281305233637492}\n",
      "{'epoch': 351, 'train_loss': 0.6573139335442748, 'val_loss': 0.6262492577234904}\n",
      "{'epoch': 352, 'train_loss': 0.6671117397232188, 'val_loss': 0.624741812547048}\n",
      "{'epoch': 353, 'train_loss': 0.6555182032494081, 'val_loss': 0.6243134101231893}\n",
      "{'epoch': 354, 'train_loss': 0.6631834892969992, 'val_loss': 0.6242326974868775}\n",
      "{'epoch': 355, 'train_loss': 0.6702257748175826, 'val_loss': 0.6246543486913045}\n",
      "{'epoch': 356, 'train_loss': 0.6559894997626543, 'val_loss': 0.625727903842926}\n",
      "{'epoch': 357, 'train_loss': 0.6569910208280716, 'val_loss': 0.6263388673464457}\n",
      "{'epoch': 358, 'train_loss': 0.6531367661534913, 'val_loss': 0.6269698937733968}\n",
      "{'epoch': 359, 'train_loss': 0.6592624777824514, 'val_loss': 0.6280563950538636}\n",
      "{'epoch': 360, 'train_loss': 0.643202291491131, 'val_loss': 0.6289866209030152}\n",
      "{'epoch': 361, 'train_loss': 0.6461980696250167, 'val_loss': 0.628845489025116}\n",
      "{'epoch': 362, 'train_loss': 0.6511759798870318, 'val_loss': 0.6283590277036031}\n",
      "{'epoch': 363, 'train_loss': 0.6575025757774711, 'val_loss': 0.6280523459116618}\n",
      "{'epoch': 364, 'train_loss': 0.6554205716691084, 'val_loss': 0.6279537598292033}\n",
      "{'epoch': 365, 'train_loss': 0.6547482484020293, 'val_loss': 0.627381694316864}\n",
      "{'epoch': 366, 'train_loss': 0.653564217655609, 'val_loss': 0.6256255904833475}\n",
      "{'epoch': 367, 'train_loss': 0.6508423045484556, 'val_loss': 0.6243470946947733}\n",
      "{'epoch': 368, 'train_loss': 0.6489639635094337, 'val_loss': 0.623415760199229}\n",
      "{'epoch': 369, 'train_loss': 0.655196642399662, 'val_loss': 0.6227953831354777}\n",
      "{'epoch': 370, 'train_loss': 0.6484412553513216, 'val_loss': 0.6222697456677755}\n",
      "{'epoch': 371, 'train_loss': 0.6578028563203083, 'val_loss': 0.6219173312187195}\n",
      "{'epoch': 372, 'train_loss': 0.6544807257337703, 'val_loss': 0.6215218226114909}\n",
      "{'epoch': 373, 'train_loss': 0.6682999148550961, 'val_loss': 0.6215264956156412}\n",
      "{'epoch': 374, 'train_loss': 0.6534867907563845, 'val_loss': 0.621897534529368}\n",
      "{'epoch': 375, 'train_loss': 0.6505538938670523, 'val_loss': 0.621383786201477}\n",
      "{'epoch': 376, 'train_loss': 0.6537027164465852, 'val_loss': 0.6212399005889893}\n",
      "{'epoch': 377, 'train_loss': 0.6535088145691488, 'val_loss': 0.6213175972302755}\n",
      "{'epoch': 378, 'train_loss': 0.6521948258806434, 'val_loss': 0.6211957534154257}\n",
      "{'epoch': 379, 'train_loss': 0.6446780623971589, 'val_loss': 0.6216941356658936}\n",
      "{'epoch': 380, 'train_loss': 0.6642488488513563, 'val_loss': 0.6223091046015421}\n",
      "{'epoch': 381, 'train_loss': 0.643458467339062, 'val_loss': 0.6234177589416504}\n",
      "{'epoch': 382, 'train_loss': 0.6438563997443352, 'val_loss': 0.6240524371465047}\n",
      "{'epoch': 383, 'train_loss': 0.6560418182052672, 'val_loss': 0.6245941718419393}\n",
      "{'epoch': 384, 'train_loss': 0.6513321001807021, 'val_loss': 0.6241288979848226}\n",
      "{'epoch': 385, 'train_loss': 0.6468037004686065, 'val_loss': 0.6232277313868204}\n",
      "{'epoch': 386, 'train_loss': 0.6642284525247911, 'val_loss': 0.6219359795252482}\n",
      "{'epoch': 387, 'train_loss': 0.6446825553559594, 'val_loss': 0.6203397393226624}\n",
      "{'epoch': 388, 'train_loss': 0.6463676629484527, 'val_loss': 0.6189064462979634}\n",
      "{'epoch': 389, 'train_loss': 0.6423516964746846, 'val_loss': 0.6183203061421713}\n",
      "{'epoch': 390, 'train_loss': 0.6456456819238762, 'val_loss': 0.6177581270535787}\n",
      "{'epoch': 391, 'train_loss': 0.6417237164763112, 'val_loss': 0.6180822968482971}\n",
      "{'epoch': 392, 'train_loss': 0.650739608073814, 'val_loss': 0.6179437597592672}\n",
      "{'epoch': 393, 'train_loss': 0.6539436453539464, 'val_loss': 0.6176970561345418}\n",
      "{'epoch': 394, 'train_loss': 0.646824625838134, 'val_loss': 0.616507883866628}\n",
      "{'epoch': 395, 'train_loss': 0.6501149395998154, 'val_loss': 0.6162367423375448}\n",
      "{'epoch': 396, 'train_loss': 0.6435207147151232, 'val_loss': 0.6166938106218973}\n",
      "{'epoch': 397, 'train_loss': 0.6476083411835134, 'val_loss': 0.6174484372138977}\n",
      "{'epoch': 398, 'train_loss': 0.6488622622047033, 'val_loss': 0.6184144457181294}\n",
      "{'epoch': 399, 'train_loss': 0.6420898820377059, 'val_loss': 0.6189504464467367}\n",
      "{'epoch': 400, 'train_loss': 0.6483789526133074, 'val_loss': 0.6189592957496644}\n",
      "{'epoch': 401, 'train_loss': 0.6436555808823969, 'val_loss': 0.6186061859130859}\n",
      "{'epoch': 402, 'train_loss': 0.6475688848230574, 'val_loss': 0.6181200504302978}\n",
      "{'epoch': 403, 'train_loss': 0.6645199490918053, 'val_loss': 0.6168753147125244}\n",
      "{'epoch': 404, 'train_loss': 0.6473733751724163, 'val_loss': 0.6166438738505046}\n",
      "{'epoch': 405, 'train_loss': 0.6679194540095825, 'val_loss': 0.6154862483342488}\n",
      "{'epoch': 406, 'train_loss': 0.6352548959871961, 'val_loss': 0.6154865582784017}\n",
      "{'epoch': 407, 'train_loss': 0.6552330365197526, 'val_loss': 0.6151630043983459}\n",
      "{'epoch': 408, 'train_loss': 0.6398445838648412, 'val_loss': 0.6153709808985393}\n",
      "{'epoch': 409, 'train_loss': 0.6381532416885926, 'val_loss': 0.615817133585612}\n",
      "{'epoch': 410, 'train_loss': 0.6330980907401277, 'val_loss': 0.6154607057571411}\n",
      "{'epoch': 411, 'train_loss': 0.6386102366054224, 'val_loss': 0.6151784181594848}\n",
      "{'epoch': 412, 'train_loss': 0.6391984268815981, 'val_loss': 0.6153164267539978}\n",
      "{'epoch': 413, 'train_loss': 0.6401133444677625, 'val_loss': 0.6150949438412984}\n",
      "{'epoch': 414, 'train_loss': 0.6491644265026681, 'val_loss': 0.614512825012207}\n",
      "{'epoch': 415, 'train_loss': 0.6414723191410303, 'val_loss': 0.6144581119219462}\n",
      "{'epoch': 416, 'train_loss': 0.6491560775062276, 'val_loss': 0.6146553039550782}\n",
      "{'epoch': 417, 'train_loss': 0.6367743823470341, 'val_loss': 0.615317722161611}\n",
      "{'epoch': 418, 'train_loss': 0.6400889010789493, 'val_loss': 0.6154757936795553}\n",
      "{'epoch': 419, 'train_loss': 0.636029024867134, 'val_loss': 0.6160182038942973}\n",
      "{'epoch': 420, 'train_loss': 0.6460864939726889, 'val_loss': 0.6165603836377461}\n",
      "{'epoch': 421, 'train_loss': 0.6397698727539844, 'val_loss': 0.6164507627487182}\n",
      "{'epoch': 422, 'train_loss': 0.6370036261052721, 'val_loss': 0.6159221450487773}\n",
      "{'epoch': 423, 'train_loss': 0.6425830618374877, 'val_loss': 0.6149962584177653}\n",
      "{'epoch': 424, 'train_loss': 0.6401716759428382, 'val_loss': 0.6144716739654541}\n",
      "{'epoch': 425, 'train_loss': 0.6476633512001071, 'val_loss': 0.6140614589055379}\n",
      "{'epoch': 426, 'train_loss': 0.6329312736375464, 'val_loss': 0.6142348647117615}\n",
      "{'epoch': 427, 'train_loss': 0.6357449208282762, 'val_loss': 0.6143052895863851}\n",
      "{'epoch': 428, 'train_loss': 0.6383113004267216, 'val_loss': 0.6145886500676473}\n",
      "{'epoch': 429, 'train_loss': 0.647802837503453, 'val_loss': 0.6134917298952738}\n",
      "{'epoch': 430, 'train_loss': 0.6370135134396453, 'val_loss': 0.612808616956075}\n",
      "{'epoch': 431, 'train_loss': 0.646563264179147, 'val_loss': 0.6120945294698079}\n",
      "{'epoch': 432, 'train_loss': 0.6378786112699244, 'val_loss': 0.6118003686269124}\n",
      "{'epoch': 433, 'train_loss': 0.6360336316025091, 'val_loss': 0.6109929283459982}\n",
      "{'epoch': 434, 'train_loss': 0.630545142158452, 'val_loss': 0.6102331479390463}\n",
      "{'epoch': 435, 'train_loss': 0.6462868303060532, 'val_loss': 0.6098733862241109}\n",
      "{'epoch': 436, 'train_loss': 0.6351233444487054, 'val_loss': 0.6098725875218709}\n",
      "{'epoch': 437, 'train_loss': 0.642851886494706, 'val_loss': 0.6095585068066914}\n",
      "{'epoch': 438, 'train_loss': 0.6461998095425466, 'val_loss': 0.6095288117726644}\n",
      "{'epoch': 439, 'train_loss': 0.6456493933478163, 'val_loss': 0.6095940391222636}\n",
      "{'epoch': 440, 'train_loss': 0.6355294681464632, 'val_loss': 0.6098642190297444}\n",
      "{'epoch': 441, 'train_loss': 0.6328356899321079, 'val_loss': 0.6094554781913757}\n",
      "{'epoch': 442, 'train_loss': 0.6475754761033587, 'val_loss': 0.6098444342613221}\n",
      "{'epoch': 443, 'train_loss': 0.6395416680412987, 'val_loss': 0.6103378574053446}\n",
      "{'epoch': 444, 'train_loss': 0.6382403948551251, 'val_loss': 0.6105367461840312}\n",
      "{'epoch': 445, 'train_loss': 0.6353866803045902, 'val_loss': 0.6098100543022156}\n",
      "{'epoch': 446, 'train_loss': 0.6434531008514265, 'val_loss': 0.6088436881701151}\n",
      "{'epoch': 447, 'train_loss': 0.6316922620559732, 'val_loss': 0.6081131060918172}\n",
      "{'epoch': 448, 'train_loss': 0.6297602557784153, 'val_loss': 0.6075411001841227}\n",
      "{'epoch': 449, 'train_loss': 0.6304405335750844, 'val_loss': 0.6073140859603882}\n",
      "{'epoch': 450, 'train_loss': 0.6401079140810503, 'val_loss': 0.6073073943456014}\n",
      "{'epoch': 451, 'train_loss': 0.6276889320255982, 'val_loss': 0.606956148147583}\n",
      "{'epoch': 452, 'train_loss': 0.6402521392123567, 'val_loss': 0.6068106373151143}\n",
      "{'epoch': 453, 'train_loss': 0.641299850307405, 'val_loss': 0.6071019570032755}\n",
      "{'epoch': 454, 'train_loss': 0.6376363578149014, 'val_loss': 0.6067894061406454}\n",
      "{'epoch': 455, 'train_loss': 0.6258298547214104, 'val_loss': 0.6070286313692729}\n",
      "{'epoch': 456, 'train_loss': 0.6322110849432647, 'val_loss': 0.6068456768989563}\n",
      "{'epoch': 457, 'train_loss': 0.6304453710714976, 'val_loss': 0.6070457220077514}\n",
      "{'epoch': 458, 'train_loss': 0.642806936107162, 'val_loss': 0.6078824321428935}\n",
      "{'epoch': 459, 'train_loss': 0.6401139816476239, 'val_loss': 0.6088861982027689}\n",
      "{'epoch': 460, 'train_loss': 0.6244183263430992, 'val_loss': 0.6087660948435465}\n",
      "{'epoch': 461, 'train_loss': 0.6251912770999802, 'val_loss': 0.6081149657567342}\n",
      "{'epoch': 462, 'train_loss': 0.6359016391345196, 'val_loss': 0.6077607870101929}\n",
      "{'epoch': 463, 'train_loss': 0.6344880786103506, 'val_loss': 0.6073029398918152}\n",
      "{'epoch': 464, 'train_loss': 0.6327988238901727, 'val_loss': 0.6069287419319153}\n",
      "{'epoch': 465, 'train_loss': 0.633800326484359, 'val_loss': 0.6067396362622579}\n",
      "{'epoch': 466, 'train_loss': 0.625981619167659, 'val_loss': 0.6069877783457438}\n",
      "{'epoch': 467, 'train_loss': 0.6311758147138689, 'val_loss': 0.6068060636520386}\n",
      "{'epoch': 468, 'train_loss': 0.6241015590623848, 'val_loss': 0.6059219201405843}\n",
      "{'epoch': 469, 'train_loss': 0.6352585732626418, 'val_loss': 0.6052336533864339}\n",
      "{'epoch': 470, 'train_loss': 0.6414502816171281, 'val_loss': 0.605332859357198}\n",
      "{'epoch': 471, 'train_loss': 0.6302965838565595, 'val_loss': 0.6054771264394124}\n",
      "{'epoch': 472, 'train_loss': 0.6268441207810409, 'val_loss': 0.6056142965952556}\n",
      "{'epoch': 473, 'train_loss': 0.6334683369948633, 'val_loss': 0.6055792927742004}\n",
      "{'epoch': 474, 'train_loss': 0.6418687998213701, 'val_loss': 0.60491331020991}\n",
      "{'epoch': 475, 'train_loss': 0.6268392170572447, 'val_loss': 0.6045785943667094}\n",
      "{'epoch': 476, 'train_loss': 0.6311902299316393, 'val_loss': 0.6044637759526571}\n",
      "{'epoch': 477, 'train_loss': 0.6207888615835044, 'val_loss': 0.6037976940472921}\n",
      "{'epoch': 478, 'train_loss': 0.6257107770070434, 'val_loss': 0.6034664670626322}\n",
      "{'epoch': 479, 'train_loss': 0.6367334614300894, 'val_loss': 0.6030688842137655}\n",
      "{'epoch': 480, 'train_loss': 0.6272615242439011, 'val_loss': 0.6027228593826294}\n",
      "{'epoch': 481, 'train_loss': 0.6383960437960923, 'val_loss': 0.6020237882932027}\n",
      "{'epoch': 482, 'train_loss': 0.6277443679153092, 'val_loss': 0.6017620166142782}\n",
      "{'epoch': 483, 'train_loss': 0.6434301571506593, 'val_loss': 0.6021425167719523}\n",
      "{'epoch': 484, 'train_loss': 0.6266113843044473, 'val_loss': 0.6031453529993693}\n",
      "{'epoch': 485, 'train_loss': 0.6331218269964058, 'val_loss': 0.6032654523849488}\n",
      "{'epoch': 486, 'train_loss': 0.6218692073598504, 'val_loss': 0.6027132272720337}\n",
      "{'epoch': 487, 'train_loss': 0.6277458377492924, 'val_loss': 0.6026183883349101}\n",
      "{'epoch': 488, 'train_loss': 0.6260278367747862, 'val_loss': 0.6030427575111389}\n",
      "{'epoch': 489, 'train_loss': 0.6387935737147927, 'val_loss': 0.6028885682423909}\n",
      "{'epoch': 490, 'train_loss': 0.629910707163314, 'val_loss': 0.6032348871231079}\n",
      "{'epoch': 491, 'train_loss': 0.6293703710349897, 'val_loss': 0.6034322381019592}\n",
      "{'epoch': 492, 'train_loss': 0.6456106494491298, 'val_loss': 0.6027393221855164}\n",
      "{'epoch': 493, 'train_loss': 0.6269042105413973, 'val_loss': 0.6014877438545227}\n",
      "{'epoch': 494, 'train_loss': 0.6295038849736253, 'val_loss': 0.6007549881935119}\n",
      "{'epoch': 495, 'train_loss': 0.6346824584632285, 'val_loss': 0.6010714173316956}\n",
      "{'epoch': 496, 'train_loss': 0.6282741527280046, 'val_loss': 0.6016107281049092}\n",
      "{'epoch': 497, 'train_loss': 0.6250999490213063, 'val_loss': 0.6014496485392252}\n",
      "{'epoch': 498, 'train_loss': 0.6237961422755487, 'val_loss': 0.6008033792177836}\n",
      "{'epoch': 499, 'train_loss': 0.6259692885602514, 'val_loss': 0.600635580221812}\n",
      "{'epoch': 500, 'train_loss': 0.6190821910277009, 'val_loss': 0.6007716695467631}\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "epoch_loop = tqdm(range(epochs), desc=\"Training Progress\", total=epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred = model(X_batch.float())\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_losses.append(train_loss / len(train_dataloader))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(X_val.float())\n",
    "        val_loss = loss_fn(y_val_pred, y_val).item()\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch+1, \n",
    "        \"train_loss\": train_losses[-1], \n",
    "        \"val_loss\": val_losses[-1]\n",
    "    }, commit=True)\n",
    "\n",
    "    print({\n",
    "        \"epoch\": epoch+1, \n",
    "        \"train_loss\": train_losses[-1], \n",
    "        \"val_loss\": val_losses[-1]\n",
    "    })\n",
    "    \n",
    "    epoch_loop.update(1)\n",
    "    epoch_loop.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    epoch_loop.set_postfix(train_loss=train_losses[-1], val_loss=val_losses[-1])\n",
    "\n",
    "epoch_loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0, 2, 1, 1, 0, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 2, 0, 0,\n",
       "       2, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0, 2, 1, 1, 0, 2, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 2, 0, 0,\n",
       "       2, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_accuracy': 0.9666666666666667, 'precision': 0.9708333333333333, 'recall': 0.9666666666666667, 'f1_score': 0.9669841269841268}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>████▇▇▇▆▆▅▅▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█████▇▇▇▆▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>500</td></tr><tr><td>f1_score</td><td>0.96698</td></tr><tr><td>precision</td><td>0.97083</td></tr><tr><td>recall</td><td>0.96667</td></tr><tr><td>test_accuracy</td><td>0.96667</td></tr><tr><td>train_loss</td><td>0.61908</td></tr><tr><td>val_loss</td><td>0.60077</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-leaf-14</strong> at: <a href='https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6/runs/yf216x6a' target=\"_blank\">https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6/runs/yf216x6a</a><br> View project at: <a href='https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6' target=\"_blank\">https://wandb.ai/23110222-indian-institute-of-technology-gandhinagar/cs203-assignment-6</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250224_020703-yf216x6a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_test_pred = model(X_test.float())\n",
    "    test_loss = loss_fn(y_test_pred, y_test).item()\n",
    "    test_acc = (y_test_pred.argmax(1) == y_test.argmax(1)).sum().item() / len(y_test)\n",
    "\n",
    "y_true = torch.argmax(y_test, dim=1).cpu().numpy()\n",
    "y_pred = y_test_pred.argmax(1).cpu().numpy()\n",
    "\n",
    "display(y_true, y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "print({\n",
    "    \"test_accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1_score\n",
    "})\n",
    "\n",
    "wandb.log({\n",
    "    \"test_accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1_score\n",
    "}, commit=True)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "class_labels = iris.target_names\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "im = ax.imshow(conf_matrix, cmap=\"Blues\", interpolation=\"nearest\")\n",
    "\n",
    "plt.colorbar(im)\n",
    "\n",
    "ax.set_xticks(np.arange(len(class_labels)))\n",
    "ax.set_yticks(np.arange(len(class_labels)))\n",
    "ax.set_xticklabels(class_labels, rotation=45)\n",
    "ax.set_yticklabels(class_labels)\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(j, i, str(conf_matrix[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "wandb.log({\n",
    "    \"Confusion Matrix\": wandb.Image(fig)\n",
    "}, commit=True)\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(range(1, epochs+1), train_losses, label=\"Training Loss\")\n",
    "ax.plot(range(1, epochs+1), val_losses, label=\"Validation Loss\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Training & Validation Loss Curve\")\n",
    "ax.legend()\n",
    "\n",
    "wandb.log({\n",
    "    \"Loss Curve\": \n",
    "    wandb.Image(fig)\n",
    "}, commit=True)\n",
    "\n",
    "plt.close(fig)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
