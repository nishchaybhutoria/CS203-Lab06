{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: MLP Model Implementation & Experiment Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement a Multi-Layer Perceptron (MLP) Using the Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0+cu124\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.4\n",
      "GPU Name: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([150])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = torch.tensor(iris.data)\n",
    "y = torch.tensor(iris.target)\n",
    "\n",
    "display(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Feature Values to [0, 1] and One-hot Encoding the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2222, 0.6250, 0.0678, 0.0417],\n",
       "        [0.1667, 0.4167, 0.0678, 0.0417],\n",
       "        [0.1111, 0.5000, 0.0508, 0.0417],\n",
       "        [0.0833, 0.4583, 0.0847, 0.0417],\n",
       "        [0.1944, 0.6667, 0.0678, 0.0417],\n",
       "        [0.3056, 0.7917, 0.1186, 0.1250],\n",
       "        [0.0833, 0.5833, 0.0678, 0.0833],\n",
       "        [0.1944, 0.5833, 0.0847, 0.0417],\n",
       "        [0.0278, 0.3750, 0.0678, 0.0417],\n",
       "        [0.1667, 0.4583, 0.0847, 0.0000],\n",
       "        [0.3056, 0.7083, 0.0847, 0.0417],\n",
       "        [0.1389, 0.5833, 0.1017, 0.0417],\n",
       "        [0.1389, 0.4167, 0.0678, 0.0000],\n",
       "        [0.0000, 0.4167, 0.0169, 0.0000],\n",
       "        [0.4167, 0.8333, 0.0339, 0.0417],\n",
       "        [0.3889, 1.0000, 0.0847, 0.1250],\n",
       "        [0.3056, 0.7917, 0.0508, 0.1250],\n",
       "        [0.2222, 0.6250, 0.0678, 0.0833],\n",
       "        [0.3889, 0.7500, 0.1186, 0.0833],\n",
       "        [0.2222, 0.7500, 0.0847, 0.0833],\n",
       "        [0.3056, 0.5833, 0.1186, 0.0417],\n",
       "        [0.2222, 0.7083, 0.0847, 0.1250],\n",
       "        [0.0833, 0.6667, 0.0000, 0.0417],\n",
       "        [0.2222, 0.5417, 0.1186, 0.1667],\n",
       "        [0.1389, 0.5833, 0.1525, 0.0417],\n",
       "        [0.1944, 0.4167, 0.1017, 0.0417],\n",
       "        [0.1944, 0.5833, 0.1017, 0.1250],\n",
       "        [0.2500, 0.6250, 0.0847, 0.0417],\n",
       "        [0.2500, 0.5833, 0.0678, 0.0417],\n",
       "        [0.1111, 0.5000, 0.1017, 0.0417],\n",
       "        [0.1389, 0.4583, 0.1017, 0.0417],\n",
       "        [0.3056, 0.5833, 0.0847, 0.1250],\n",
       "        [0.2500, 0.8750, 0.0847, 0.0000],\n",
       "        [0.3333, 0.9167, 0.0678, 0.0417],\n",
       "        [0.1667, 0.4583, 0.0847, 0.0417],\n",
       "        [0.1944, 0.5000, 0.0339, 0.0417],\n",
       "        [0.3333, 0.6250, 0.0508, 0.0417],\n",
       "        [0.1667, 0.6667, 0.0678, 0.0000],\n",
       "        [0.0278, 0.4167, 0.0508, 0.0417],\n",
       "        [0.2222, 0.5833, 0.0847, 0.0417],\n",
       "        [0.1944, 0.6250, 0.0508, 0.0833],\n",
       "        [0.0556, 0.1250, 0.0508, 0.0833],\n",
       "        [0.0278, 0.5000, 0.0508, 0.0417],\n",
       "        [0.1944, 0.6250, 0.1017, 0.2083],\n",
       "        [0.2222, 0.7500, 0.1525, 0.1250],\n",
       "        [0.1389, 0.4167, 0.0678, 0.0833],\n",
       "        [0.2222, 0.7500, 0.1017, 0.0417],\n",
       "        [0.0833, 0.5000, 0.0678, 0.0417],\n",
       "        [0.2778, 0.7083, 0.0847, 0.0417],\n",
       "        [0.1944, 0.5417, 0.0678, 0.0417],\n",
       "        [0.7500, 0.5000, 0.6271, 0.5417],\n",
       "        [0.5833, 0.5000, 0.5932, 0.5833],\n",
       "        [0.7222, 0.4583, 0.6610, 0.5833],\n",
       "        [0.3333, 0.1250, 0.5085, 0.5000],\n",
       "        [0.6111, 0.3333, 0.6102, 0.5833],\n",
       "        [0.3889, 0.3333, 0.5932, 0.5000],\n",
       "        [0.5556, 0.5417, 0.6271, 0.6250],\n",
       "        [0.1667, 0.1667, 0.3898, 0.3750],\n",
       "        [0.6389, 0.3750, 0.6102, 0.5000],\n",
       "        [0.2500, 0.2917, 0.4915, 0.5417],\n",
       "        [0.1944, 0.0000, 0.4237, 0.3750],\n",
       "        [0.4444, 0.4167, 0.5424, 0.5833],\n",
       "        [0.4722, 0.0833, 0.5085, 0.3750],\n",
       "        [0.5000, 0.3750, 0.6271, 0.5417],\n",
       "        [0.3611, 0.3750, 0.4407, 0.5000],\n",
       "        [0.6667, 0.4583, 0.5763, 0.5417],\n",
       "        [0.3611, 0.4167, 0.5932, 0.5833],\n",
       "        [0.4167, 0.2917, 0.5254, 0.3750],\n",
       "        [0.5278, 0.0833, 0.5932, 0.5833],\n",
       "        [0.3611, 0.2083, 0.4915, 0.4167],\n",
       "        [0.4444, 0.5000, 0.6441, 0.7083],\n",
       "        [0.5000, 0.3333, 0.5085, 0.5000],\n",
       "        [0.5556, 0.2083, 0.6610, 0.5833],\n",
       "        [0.5000, 0.3333, 0.6271, 0.4583],\n",
       "        [0.5833, 0.3750, 0.5593, 0.5000],\n",
       "        [0.6389, 0.4167, 0.5763, 0.5417],\n",
       "        [0.6944, 0.3333, 0.6441, 0.5417],\n",
       "        [0.6667, 0.4167, 0.6780, 0.6667],\n",
       "        [0.4722, 0.3750, 0.5932, 0.5833],\n",
       "        [0.3889, 0.2500, 0.4237, 0.3750],\n",
       "        [0.3333, 0.1667, 0.4746, 0.4167],\n",
       "        [0.3333, 0.1667, 0.4576, 0.3750],\n",
       "        [0.4167, 0.2917, 0.4915, 0.4583],\n",
       "        [0.4722, 0.2917, 0.6949, 0.6250],\n",
       "        [0.3056, 0.4167, 0.5932, 0.5833],\n",
       "        [0.4722, 0.5833, 0.5932, 0.6250],\n",
       "        [0.6667, 0.4583, 0.6271, 0.5833],\n",
       "        [0.5556, 0.1250, 0.5763, 0.5000],\n",
       "        [0.3611, 0.4167, 0.5254, 0.5000],\n",
       "        [0.3333, 0.2083, 0.5085, 0.5000],\n",
       "        [0.3333, 0.2500, 0.5763, 0.4583],\n",
       "        [0.5000, 0.4167, 0.6102, 0.5417],\n",
       "        [0.4167, 0.2500, 0.5085, 0.4583],\n",
       "        [0.1944, 0.1250, 0.3898, 0.3750],\n",
       "        [0.3611, 0.2917, 0.5424, 0.5000],\n",
       "        [0.3889, 0.4167, 0.5424, 0.4583],\n",
       "        [0.3889, 0.3750, 0.5424, 0.5000],\n",
       "        [0.5278, 0.3750, 0.5593, 0.5000],\n",
       "        [0.2222, 0.2083, 0.3390, 0.4167],\n",
       "        [0.3889, 0.3333, 0.5254, 0.5000],\n",
       "        [0.5556, 0.5417, 0.8475, 1.0000],\n",
       "        [0.4167, 0.2917, 0.6949, 0.7500],\n",
       "        [0.7778, 0.4167, 0.8305, 0.8333],\n",
       "        [0.5556, 0.3750, 0.7797, 0.7083],\n",
       "        [0.6111, 0.4167, 0.8136, 0.8750],\n",
       "        [0.9167, 0.4167, 0.9492, 0.8333],\n",
       "        [0.1667, 0.2083, 0.5932, 0.6667],\n",
       "        [0.8333, 0.3750, 0.8983, 0.7083],\n",
       "        [0.6667, 0.2083, 0.8136, 0.7083],\n",
       "        [0.8056, 0.6667, 0.8644, 1.0000],\n",
       "        [0.6111, 0.5000, 0.6949, 0.7917],\n",
       "        [0.5833, 0.2917, 0.7288, 0.7500],\n",
       "        [0.6944, 0.4167, 0.7627, 0.8333],\n",
       "        [0.3889, 0.2083, 0.6780, 0.7917],\n",
       "        [0.4167, 0.3333, 0.6949, 0.9583],\n",
       "        [0.5833, 0.5000, 0.7288, 0.9167],\n",
       "        [0.6111, 0.4167, 0.7627, 0.7083],\n",
       "        [0.9444, 0.7500, 0.9661, 0.8750],\n",
       "        [0.9444, 0.2500, 1.0000, 0.9167],\n",
       "        [0.4722, 0.0833, 0.6780, 0.5833],\n",
       "        [0.7222, 0.5000, 0.7966, 0.9167],\n",
       "        [0.3611, 0.3333, 0.6610, 0.7917],\n",
       "        [0.9444, 0.3333, 0.9661, 0.7917],\n",
       "        [0.5556, 0.2917, 0.6610, 0.7083],\n",
       "        [0.6667, 0.5417, 0.7966, 0.8333],\n",
       "        [0.8056, 0.5000, 0.8475, 0.7083],\n",
       "        [0.5278, 0.3333, 0.6441, 0.7083],\n",
       "        [0.5000, 0.4167, 0.6610, 0.7083],\n",
       "        [0.5833, 0.3333, 0.7797, 0.8333],\n",
       "        [0.8056, 0.4167, 0.8136, 0.6250],\n",
       "        [0.8611, 0.3333, 0.8644, 0.7500],\n",
       "        [1.0000, 0.7500, 0.9153, 0.7917],\n",
       "        [0.5833, 0.3333, 0.7797, 0.8750],\n",
       "        [0.5556, 0.3333, 0.6949, 0.5833],\n",
       "        [0.5000, 0.2500, 0.7797, 0.5417],\n",
       "        [0.9444, 0.4167, 0.8644, 0.9167],\n",
       "        [0.5556, 0.5833, 0.7797, 0.9583],\n",
       "        [0.5833, 0.4583, 0.7627, 0.7083],\n",
       "        [0.4722, 0.4167, 0.6441, 0.7083],\n",
       "        [0.7222, 0.4583, 0.7458, 0.8333],\n",
       "        [0.6667, 0.4583, 0.7797, 0.9583],\n",
       "        [0.7222, 0.4583, 0.6949, 0.9167],\n",
       "        [0.4167, 0.2917, 0.6949, 0.7500],\n",
       "        [0.6944, 0.5000, 0.8305, 0.9167],\n",
       "        [0.6667, 0.5417, 0.7966, 1.0000],\n",
       "        [0.6667, 0.4167, 0.7119, 0.9167],\n",
       "        [0.5556, 0.2083, 0.6780, 0.7500],\n",
       "        [0.6111, 0.4167, 0.7119, 0.7917],\n",
       "        [0.5278, 0.5833, 0.7458, 0.9167],\n",
       "        [0.4444, 0.4167, 0.6949, 0.7083]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = torch.tensor(scaler.fit_transform(X)).to(device)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y = torch.tensor(encoder.fit_transform(y.reshape(-1, 1)).toarray()).to(device)\n",
    "\n",
    "display(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "display(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define and Train the MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=16, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=16, out_features=3, bias=True)\n",
       "  (3): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 3),\n",
    "    nn.Softmax(dim=1)\n",
    ").to(device)\n",
    "\n",
    "display(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
